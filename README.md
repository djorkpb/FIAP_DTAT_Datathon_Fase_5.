# **Decision Match AI ğŸ¤–**

## **ğŸ“ DescriÃ§Ã£o do Projeto**

Este projeto foi desenvolvido como soluÃ§Ã£o para o **Datathon Decision**, um desafio focado em aplicar InteligÃªncia Artificial para otimizar os processos de recrutamento e seleÃ§Ã£o da empresa Decision, uma especialista em bodyshop de TI.

A soluÃ§Ã£o proposta Ã© o **Decision Match AI**, um sistema de recomendaÃ§Ã£o inteligente para otimizaÃ§Ã£o do recrutamento com InteligÃªncia Artificial. A ferramenta utiliza um modelo de Machine Learning para analisar o perfil de um candidato em relaÃ§Ã£o a uma vaga e gerar um **"score de compatibilidade"**. O objetivo Ã© ranquear os candidatos, permitindo que o time de recrutadores foque seu tempo e energia nos perfis mais promissores.

Para garantir alta performance e portabilidade, a aplicaÃ§Ã£o foi arquitetada para carregar um modelo treinado e artefatos de dados prÃ©-processados diretamente da nuvem, garantindo um carregamento rÃ¡pido e uma experiÃªncia de utilizador fluida.

O pipeline de Machine Learning foi construÃ­do seguindo as melhores prÃ¡ticas de MLOps, incluindo etapas de processamento de dados, engenharia de features, competiÃ§Ã£o entre mÃºltiplos modelos (RegressÃ£o LogÃ­stica, XGBoost, LightGBM e CatBoost), avaliaÃ§Ã£o de mÃ©tricas e testes unitÃ¡rios.

## **ğŸ› ï¸ Stack Utilizada**

* **Linguagem:** Python 3  
* **AnÃ¡lise e Processamento de Dados:** Pandas, NumPy, Parquet (pyarrow)  
* **Machine Learning:** Scikit-learn, XGBoost, LightGBM, CatBoost  
* **Web App (Dashboard):** Streamlit  
* **SerializaÃ§Ã£o de Artefatos:** Joblib  
* **Testes:** Pytest

## **ğŸ“‚ Estrutura do RepositÃ³rio**

â”œâ”€â”€ app/  
â”‚   â””â”€â”€ app.py                  \# Script principal da aplicaÃ§Ã£o com Streamlit  
â”œâ”€â”€ artifacts/  
â”‚   â”œâ”€â”€ applicants\_processed.parquet  \# DataFrame de candidatos otimizado  
â”‚   â”œâ”€â”€ tfidf\_matrix.joblib         \# Matriz TF-IDF prÃ©-calculada  
â”‚   â””â”€â”€ tfidf\_vectorizer.joblib     \# Vetorizador TF-IDF treinado  
â”œâ”€â”€ data/  
â”‚   â”œâ”€â”€ raw/                    \# Onde os dados brutos em JSON devem ser colocados  
â”‚   â””â”€â”€ processed/              \# Arquivos intermediÃ¡rios gerados pelo pipeline  
â”œâ”€â”€ models/  
â”‚   â””â”€â”€ modelo\_decision\_match\_ai.joblib \# Modelo vencedor treinado e serializado  
â”œâ”€â”€ notebooks/  
â”‚   â”œâ”€â”€ 1\_Data\_Processing.ipynb     \# Notebook da Etapa 1: ConsolidaÃ§Ã£o dos Dados  
â”‚   â””â”€â”€ 2\_Feature\_Engineering.ipynb \# Notebook da Etapa 2: CriaÃ§Ã£o de Features  
â”œâ”€â”€ results/  
â”‚   â”œâ”€â”€ metrics.json            \# MÃ©tricas de performance do modelo vencedor  
â”‚   â””â”€â”€ matriz\_confusao.png     \# Imagem da matriz de confusÃ£o  
â”œâ”€â”€ src/  
â”‚   â”œâ”€â”€ app\_utils.py            \# FunÃ§Ãµes de lÃ³gica da aplicaÃ§Ã£o Streamlit  
â”‚   â”œâ”€â”€ train.py                \# Script para treino e seleÃ§Ã£o do melhor modelo  
â”‚   â””â”€â”€ evaluate.py             \# Script para avaliaÃ§Ã£o do modelo vencedor  
â”œâ”€â”€ tests/  
â”‚   â”œâ”€â”€ \_\_init\_\_.py  
â”‚   â”œâ”€â”€ mock\_data.py            \# Dados falsos para os testes  
â”‚   â””â”€â”€ test\_app\_functions.py   \# Testes unitÃ¡rios das funÃ§Ãµes  
â”œâ”€â”€ .gitignore                    \# Arquivo para ignorar pastas e arquivos  
â”œâ”€â”€ build\_artifacts.py          \# Script para gerar os artefatos de performance  
â”œâ”€â”€ README.md                     \# DocumentaÃ§Ã£o do projeto  
â””â”€â”€ requirements.txt              \# Bibliotecas e versÃµes para o ambiente

## **ğŸš€ Como Rodar a AplicaÃ§Ã£o (Modo Simples)**

Esta Ã© a forma mais rÃ¡pida de executar a aplicaÃ§Ã£o, pois ela carrega todos os dados e modelos prÃ©-processados diretamente da nuvem.

**1\. PrÃ©-requisitos:**

* Ter o [Python 3.8+](https://www.python.org/downloads/) instalado.  
* Ter o pip (gestor de pacotes do Python) instalado.

**2\. Clone o RepositÃ³rio:**

git clone \[URL\_DO\_SEU\_REPOSITORIO\]  
cd \[NOME\_DA\_PASTA\_DO\_PROJETO\]

**3\. Crie um Ambiente Virtual (Recomendado):**

\# Para Windows  
python \-m venv venv  
venv\\Scripts\\activate

\# Para macOS/Linux  
python3 \-m venv venv  
source venv/bin/activate

**4\. Instale as DependÃªncias:**

pip install \-r requirements.txt

**5\. Inicie a AplicaÃ§Ã£o Streamlit:**

streamlit run app/app.py

**Nota 1:** A aplicaÃ§Ã£o jÃ¡ estÃ¡ configurada para buscar os arquivos das URLs definidas no topo do src/app\_utils.py. Certifique-se de que essas URLs estejam corretas e acessÃ­veis.

**Nota 2:** Para fazer o deploy no Streamlit.io Ã© necessÃ¡rio definir a versÃ£o do Python 3.12 (Advanced settings).

## **âš™ï¸ Como Reproduzir o Pipeline Completo (Do Zero)**

Siga estes passos se vocÃª deseja processar os dados brutos, treinar um novo modelo e gerar os artefatos do zero.

**Execute todos os comandos a partir do diretÃ³rio raiz do projeto.**

**Etapa 1: Processamento de Dados (Notebooks)**

1. Coloque os arquivos de dados brutos (vagas.json, prospects.json, applicants.json) no diretÃ³rio data/raw/.  
2. Execute os notebooks Jupyter na seguinte ordem:  
   * notebooks/1\_Data\_Processing.ipynb  
   * notebooks/2\_Feature\_Engineering.ipynb

**Etapa 2: Treino e AvaliaÃ§Ã£o do Modelo (Scripts)**

1. **Treinar o modelo:**  
   python src/train.py

   Isto irÃ¡ gerar o arquivo models/modelo\_decision\_match\_ai.joblib.

2. **Avaliar o modelo vencedor:**  
   python src/evaluate.py

   Isto irÃ¡ gerar os arquivos de mÃ©tricas e a matriz de confusÃ£o na pasta results/.

**Etapa 3: Gerar Artefatos de Performance**

1. Este Ã© um passo crucial para otimizar a aplicaÃ§Ã£o Streamlit. Execute o script:  
   python build\_artifacts.py

   Isto irÃ¡ criar a pasta artifacts/ com os arquivos applicants\_processed.parquet, tfidf\_vectorizer.joblib e tfidf\_matrix.joblib.

**Etapa 4: Fazer Upload dos Artefatos (Opcional, para Deploy)**

1. FaÃ§a o upload dos artefatos gerados para um serviÃ§o de hospedagem (como GitHub Releases):  
   * models/modelo\_decision\_match\_ai.joblib  
   * artifacts/applicants\_processed.parquet  
   * artifacts/tfidf\_vectorizer.joblib  
   * artifacts/tfidf\_matrix.joblib  
   * data/processed/vagas\_cleaned.json  
2. Atualize as constantes de URL no topo do arquivo src/app\_utils.py com os novos links.

**Etapa 5: Iniciar a AplicaÃ§Ã£o Streamlit**

streamlit run app/app.py  
