# **Decision Match AI ğŸ¤–**

## **ğŸ“ DescriÃ§Ã£o do Projeto**

Este projeto foi desenvolvido como soluÃ§Ã£o para o **Datathon Decision**, um desafio focado em aplicar InteligÃªncia Artificial para otimizar os processos de recrutamento e seleÃ§Ã£o da empresa Decision, uma especialista em bodyshop de TI.

O principal desafio da Decision Ã© encontrar o talento ideal para cada vaga de forma Ã¡gil e precisa. O processo atual, embora robusto, enfrenta dores como a falta de padronizaÃ§Ã£o em entrevistas e a dificuldade em escalar a anÃ¡lise de um grande volume de candidatos.

A soluÃ§Ã£o proposta Ã© o **Decision Match AI**, um MVP (Minimum Viable Product) de um sistema de recomendaÃ§Ã£o inteligente. A ferramenta utiliza um modelo de Machine Learning para analisar o perfil de um candidato em relaÃ§Ã£o a uma vaga e gerar um **"score de compatibilidade"**. O objetivo Ã© ranquear os candidatos, permitindo que o time de recrutadores foque seu tempo e energia nos perfis mais promissores, otimizando todo o fluxo de seleÃ§Ã£o.

O pipeline de Machine Learning foi construÃ­do seguindo as melhores prÃ¡ticas de MLOps, incluindo etapas de processamento de dados, engenharia de features, competiÃ§Ã£o entre mÃºltiplos modelos (RegressÃ£o LogÃ­stica, XGBoost, LightGBM, CatBoost) com otimizaÃ§Ã£o de hiperparÃ¢metros, avaliaÃ§Ã£o de mÃ©tricas e testes unitÃ¡rios para garantir a robustez da soluÃ§Ã£o.

## **ğŸ› ï¸ Stack Utilizada**

* **Linguagem:** Python 3  
* **AnÃ¡lise e Processamento de Dados:** Pandas, NumPy  
* **Machine Learning:** Scikit-learn, XGBoost, LightGBM, CatBoost  
* **Web App (Dashboard):** Streamlit  
* **VisualizaÃ§Ã£o de Dados:** Matplotlib, Seaborn  
* **SerializaÃ§Ã£o do Modelo:** Joblib  
* **Testes:** Pytest

## **ğŸ“‚ Estrutura do RepositÃ³rio**

â”œâ”€â”€ app/  
â”‚   â””â”€â”€ app.py                  \# Script principal da aplicaÃ§Ã£o com Streamlit  
â”œâ”€â”€ data/  
â”‚   â”œâ”€â”€ raw/                    \# Onde os dados brutos em JSON devem ser colocados  
â”‚   â””â”€â”€ processed/              \# Ficheiros intermediÃ¡rios gerados pelo pipeline (ignorados pelo .gitignore)  
â”œâ”€â”€ models/  
â”‚   â””â”€â”€ modelo\_decision\_match\_ai.joblib \# Modelo vencedor treinado e serializado  
â”œâ”€â”€ notebooks/  
â”‚   â”œâ”€â”€ 1\_Data\_Processing.ipynb     \# Notebook da Etapa 1: ConsolidaÃ§Ã£o dos Dados  
â”‚   â”œâ”€â”€ 2\_Feature\_Engineering.ipynb \# Notebook da Etapa 2: CriaÃ§Ã£o de Features  
â”œâ”€â”€ results/  
â”‚   â”œâ”€â”€ metrics.json            \# MÃ©tricas de performance do modelo vencedor  
â”‚   â””â”€â”€ matriz\_confusao.png     \# Imagem da matriz de confusÃ£o  
â”œâ”€â”€ src/  
â”‚   â”œâ”€â”€ \_\_init\_\_.py  
â”‚   â”œâ”€â”€ app\_utils.py            \# FunÃ§Ãµes de lÃ³gica da aplicaÃ§Ã£o Streamlit  
â”‚   â”œâ”€â”€ train.py                \# Script para treino e seleÃ§Ã£o do melhor modelo  
â”‚   â””â”€â”€ evaluate.py             \# Script para avaliaÃ§Ã£o do modelo vencedor  
â”œâ”€â”€ tests/  
â”‚   â”œâ”€â”€ \_\_init\_\_.py  
â”‚   â”œâ”€â”€ mock\_data.py            \# Dados falsos para os testes  
â”‚   â””â”€â”€ test\_app\_functions.py   \# Testes unitÃ¡rios das funÃ§Ãµes  
â”œâ”€â”€ .gitignore                    \# Ficheiro para ignorar pastas e ficheiros  
â”œâ”€â”€ README.md                     \# DocumentaÃ§Ã£o do projeto  
â””â”€â”€ requirements.txt              \# Bibliotecas e versÃµes para o ambiente

## **âš™ï¸ InstruÃ§Ãµes de InstalaÃ§Ã£o**

Para executar este projeto localmente, siga os passos abaixo.

**1\. PrÃ©-requisitos:**

* Ter o [Python 3.8+](https://www.python.org/downloads/) instalado.  
* Ter o pip (gestor de pacotes do Python) instalado.

**2\. Clone o RepositÃ³rio:**

git clone \[https://github.com/SEU\_USUARIO/SEU\_REPOSITORIO.git\](https://github.com/SEU\_USUARIO/SEU\_REPOSITORIO.git)  
cd SEU\_REPOSITORIO

**3\. Crie um Ambiente Virtual (Recomendado):**

\# Para Windows  
python \-m venv venv  
venv\\Scripts\\activate

\# Para macOS/Linux  
python3 \-m venv venv  
source venv/bin/activate

**4\. Instale as DependÃªncias:**

pip install \-r requirements.txt

## **ğŸš€ Pipeline de ExecuÃ§Ã£o (Ordem Correta)**

Para gerar os resultados do zero, siga esta ordem de execuÃ§Ã£o. **Execute todos os comandos a partir do diretÃ³rio raiz do projeto** (ex: Tech5/).

**Etapa 1: Processamento de Dados (Notebooks)**

* Coloque os ficheiros de dados brutos (vagas.json, prospects.json, applicants.json) no diretÃ³rio data/raw/.  
* Execute os notebooks Jupyter na seguinte ordem:  
  1. notebooks/1\_Data\_Processing.ipynb  
  2. notebooks/2\_Feature\_Engineering.ipynb

**Etapa 2: Treino e AvaliaÃ§Ã£o do Modelo (Scripts)**

* Execute os scripts Python a partir do terminal:  
  1. **Treinar o modelo:**  
     python src/train.py

  2. **Avaliar o modelo vencedor:**  
     python src/evaluate.py

**Etapa 3: Executar Testes UnitÃ¡rios (Opcional)**

* Para verificar a integridade das funÃ§Ãµes:  
  pytest

**Etapa 4: Iniciar a AplicaÃ§Ã£o Streamlit**

* Para interagir com a aplicaÃ§Ã£o web:  
  streamlit run app/app.py  
