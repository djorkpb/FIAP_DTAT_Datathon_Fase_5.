# **Decision Match AI ğŸ¤–**

## **ğŸ“ DescriÃ§Ã£o do Projeto**

Este projeto foi desenvolvido como soluÃ§Ã£o para o **Datathon Decision**, um desafio focado em aplicar InteligÃªncia Artificial para otimizar os processos de recrutamento e seleÃ§Ã£o da empresa Decision, uma especialista em bodyshop de TI.

A soluÃ§Ã£o proposta Ã© o **Decision Match AI**, um sistema de recomendaÃ§Ã£o inteligente. A ferramenta utiliza um modelo de Machine Learning para analisar o perfil de um candidato em relaÃ§Ã£o a uma vaga e gerar um **"score de compatibilidade"**.

O objetivo principal da ferramenta **nÃ£o Ã© encontrar todos os bons candidatos**, mas sim realizar uma **triagem de altÃ­ssima relevÃ¢ncia**. A meta Ã© eliminar eficientemente os perfis com baixa compatibilidade ("maus candidatos"), garantindo que os poucos candidatos que o recrutador analisa tenham uma probabilidade muito maior de serem adequados para a vaga, otimizando assim o tempo e a eficiÃªncia do processo seletivo.

O pipeline de Machine Learning foi construÃ­do seguindo as melhores prÃ¡ticas de MLOps, incluindo etapas de processamento de dados, engenharia de features, competiÃ§Ã£o entre mÃºltiplos modelos, avaliaÃ§Ã£o de mÃ©tricas e testes unitÃ¡rios.

## **ğŸ¯ SeleÃ§Ã£o de Modelo e Performance**

A escolha do modelo foi realizada atravÃ©s de um processo competitivo, onde algoritmos como RegressÃ£o LogÃ­stica, XGBoost, LightGBM e CatBoost foram treinados e avaliados.

### **MÃ©trica de AvaliaÃ§Ã£o: Foco na PrecisÃ£o**

Dado o objetivo de negÃ³cio de "nÃ£o fazer o recrutador perder tempo", a mÃ©trica principal para o sucesso Ã© a **PrecisÃ£o (Precision)**. Para a classe "NÃ£o Match", uma alta precisÃ£o garante que estamos a eliminar os candidatos errados de forma eficaz. Para a classe "Match", uma alta precisÃ£o garante que as recomendaÃ§Ãµes feitas sÃ£o confiÃ¡veis e de alta qualidade.

### **Resultados Finais e InterpretaÃ§Ã£o**

ApÃ³s o treino com dados balanceados (SMOTE) e o ajuste do limiar de decisÃ£o, o modelo final (CatBoost Otimizado) alcanÃ§ou as seguintes mÃ©tricas de performance no conjunto de teste:

\--- MÃ‰TRICAS DE PERFORMANCE (LIMIAR OTIMIZADO) \---  
              precision    recall  f1-score   support

           0       0.95      0.95      0.95      2615  
           1       0.22      0.23      0.22       155

    accuracy                           0.91      2770

**AnÃ¡lise Positiva dos Resultados:**

* **Excelente Triagem (PrecisÃ£o da Classe 0 \= 95%):** O resultado mais forte do modelo Ã© a sua capacidade de identificar corretamente os "nÃ£o-matches". Quando o modelo diz que um candidato nÃ£o Ã© adequado, ele estÃ¡ correto em 95% das vezes. Isto cumpre perfeitamente o objetivo principal de **eliminar os maus candidatos** com altÃ­ssima confianÃ§a, limpando a base para o recrutador.  
* **RecomendaÃ§Ãµes de Alta RelevÃ¢ncia (PrecisÃ£o da Classe 1 \= 22%):** O modelo alcanÃ§ou uma precisÃ£o de 22% para as suas recomendaÃ§Ãµes positivas. Isto significa que, de cada 5 candidatos que a ferramenta recomenda, 1 Ã©, de facto, um "match", representando uma melhoria significativa na qualidade da triagem e na otimizaÃ§Ã£o do tempo do recrutador em comparaÃ§Ã£o a uma anÃ¡lise manual.  
* **Trade-off Intencional (Recall da Classe 1 \= 23%):** O baixo recall Ã© uma consequÃªncia direta e **intencional** da nossa estratÃ©gia. Para garantir que as recomendaÃ§Ãµes sejam de alta qualidade (alta precisÃ£o), o modelo torna-se mais seletivo e rigoroso, deixando de capturar alguns candidatos que poderiam ser adequados. Este Ã© um trade-off positivo para o cenÃ¡rio de negÃ³cio definido, que prioriza a qualidade sobre a quantidade das recomendaÃ§Ãµes.

Em resumo, o modelo final Ã© um sucesso, pois estÃ¡ perfeitamente alinhado com a estratÃ©gia de negÃ³cio de fornecer uma ferramenta de triagem precisa e que otimiza o tempo da equipa de recrutamento.

## **ğŸ› ï¸ Stack Utilizada**

* **Linguagem:** Python 3  
* **AnÃ¡lise e Processamento de Dados:** Pandas, NumPy, Parquet (pyarrow)  
* **Machine Learning:** Scikit-learn, XGBoost, LightGBM, CatBoost, Imbalanced-learn  
* **Web App (Dashboard):** Streamlit  
* **SerializaÃ§Ã£o de Artefatos:** Joblib  
* **Testes:** Pytest

## **ğŸ“‚ Estrutura do RepositÃ³rio**

â”œâ”€â”€ app/  
â”‚   â””â”€â”€ app.py                  \# Script principal da aplicaÃ§Ã£o com Streamlit  
â”œâ”€â”€ artifacts/  
â”‚   â”œâ”€â”€ applicants\_processed.parquet  \# DataFrame de candidatos otimizado  
â”‚   â”œâ”€â”€ tfidf\_matrix.joblib         \# Matriz TF-IDF prÃ©-calculada  
â”‚   â””â”€â”€ tfidf\_vectorizer.joblib     \# Vetorizador TF-IDF treinado  
â”œâ”€â”€ data/  
â”‚   â”œâ”€â”€ raw/                    \# Onde os dados brutos em JSON devem ser colocados  
â”‚   â””â”€â”€ processed/              \# Arquivos intermediÃ¡rios gerados pelo pipeline  
â”œâ”€â”€ models/  
â”‚   â””â”€â”€ modelo\_decision\_match\_ai.joblib \# Modelo vencedor treinado e serializado  
â”œâ”€â”€ notebooks/  
â”‚   â”œâ”€â”€ 1\_Data\_Processing.ipynb     \# Notebook da Etapa 1: ConsolidaÃ§Ã£o dos Dados  
â”‚   â””â”€â”€ 2\_Feature\_Engineering.ipynb \# Notebook da Etapa 2: CriaÃ§Ã£o de Features  
â”œâ”€â”€ results/  
â”‚   â”œâ”€â”€ metrics.json            \# MÃ©tricas de performance do modelo vencedor  
â”‚   â””â”€â”€ matriz\_confusao.png     \# Imagem da matriz de confusÃ£o  
â”œâ”€â”€ src/  
â”‚   â”œâ”€â”€ app\_utils.py            \# FunÃ§Ãµes de lÃ³gica da aplicaÃ§Ã£o Streamlit  
â”‚   â”œâ”€â”€ train.py                \# Script para treino e seleÃ§Ã£o do melhor modelo  
â”‚   â””â”€â”€ evaluate.py             \# Script para avaliaÃ§Ã£o do modelo vencedor  
â”œâ”€â”€ tests/  
â”‚   â”œâ”€â”€ \_\_init\_\_.py  
â”‚   â”œâ”€â”€ mock\_data.py            \# Dados falsos para os testes  
â”‚   â””â”€â”€ test\_app\_functions.py   \# Testes unitÃ¡rios das funÃ§Ãµes  
â”œâ”€â”€ .gitignore                    \# Arquivo para ignorar pastas e arquivos  
â”œâ”€â”€ build\_artifacts.py          \# Script para gerar os artefatos de performance  
â”œâ”€â”€ README.md                     \# DocumentaÃ§Ã£o do projeto  
â”œâ”€â”€ PIPELINE.md                   \# Pipeline do projeto  
â””â”€â”€ requirements.txt              \# Bibliotecas e versÃµes para o ambiente

## **ğŸš€ Como Rodar a AplicaÃ§Ã£o (Modo Simples)**

Esta Ã© a forma mais rÃ¡pida de executar a aplicaÃ§Ã£o, pois ela carrega todos os dados e modelos prÃ©-processados diretamente da nuvem.

**1\. PrÃ©-requisitos:**

* Ter o [Python 3.11](https://www.python.org/downloads/) instalado.  
* Ter o pip (gestor de pacotes do Python) instalado.

**2\. Clone o RepositÃ³rio:**

git clone \[URL\_DO\_SEU\_REPOSITORIO\]  
cd \[NOME\_DA\_PASTA\_DO\_PROJETO\]

**3\. Crie um Ambiente Virtual (Recomendado):**

\# Para Windows  
python \-m venv venv  
venv\\Scripts\\activate

\# Para macOS/Linux  
python3 \-m venv venv  
source venv/bin/activate

**4\. Instale as DependÃªncias:**

pip install \-r requirements.txt

**5\. Inicie a AplicaÃ§Ã£o Streamlit:**

streamlit run app/app.py

**Nota:** A aplicaÃ§Ã£o jÃ¡ estÃ¡ configurada para buscar os arquivos das URLs definidas no topo do src/app\_utils.py. Certifique-se de que essas URLs estejam corretas e acessÃ­veis.

## **âš™ï¸ Como Reproduzir o Pipeline Completo (Do Zero)**

Siga estes passos se vocÃª deseja processar os dados brutos, treinar um novo modelo e gerar os artefatos do zero.

**Execute todos os comandos a partir do diretÃ³rio raiz do projeto.**

**Etapa 1: Processamento de Dados (Notebooks)**

1. Coloque os arquivos de dados brutos (vagas.json, prospects.json, applicants.json) no diretÃ³rio data/raw/.  
2. Execute os notebooks Jupyter na seguinte ordem:  
   * notebooks/1\_Data\_Processing.ipynb  
   * notebooks/2\_Feature\_Engineering.ipynb

**Etapa 2: Treino e AvaliaÃ§Ã£o do Modelo (Scripts)**

1. **Treinar o modelo:**  
   python src/train.py

   Isto irÃ¡ gerar o arquivo models/modelo\_decision\_match\_ai.joblib.  
2. **Avaliar o modelo vencedor:**  
   python src/evaluate.py

   Isto irÃ¡ gerar os arquivos de mÃ©tricas e a matriz de confusÃ£o na pasta results/.

**Etapa 3: Gerar Artefatos de Performance**

1. Este Ã© um passo crucial para otimizar a aplicaÃ§Ã£o Streamlit. Execute o script:  
   python build\_artifacts.py

   Isto irÃ¡ criar a pasta artifacts/ com os arquivos applicants\_processed.parquet, tfidf\_vectorizer.joblib e tfidf\_matrix.joblib.

**Etapa 4: Fazer Upload dos Artefatos (Opcional, para Deploy)**

1. FaÃ§a o upload dos artefatos gerados para um serviÃ§o de hospedagem (como GitHub Releases):  
   * models/modelo\_decision\_match\_ai.joblib  
   * artifacts/applicants\_processed.parquet  
   * artifacts/tfidf\_vectorizer.joblib  
   * artifacts/tfidf\_matrix.joblib  
   * data/processed/vagas\_cleaned.json  
2. Atualize as constantes de URL no topo do arquivo src/app\_utils.py com os novos links.

**Etapa 5: Iniciar a AplicaÃ§Ã£o Streamlit**

streamlit run app/app.py  
