{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 1: Processamento e Consolidação dos Dados\n",
    "\n",
    "Neste notebook, vamos ler os três ficheiros JSON brutos (`vagas`, `prospects`, `applicants`), limpá-los e padronizá-los na origem, uni-los numa única base de dados e aplicar os filtros de negócio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ETAPA 1: PROCESSAMENTO E CONSOLIDAÇÃO DOS DADOS ---\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "\n",
    "print(\"--- ETAPA 1: PROCESSAMENTO E CONSOLIDAÇÃO DOS DADOS ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bloco 1: Processar `vagas.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processando vagas.json...\n",
      "Níveis de idioma das vagas foram limpos e padronizados.\n",
      "vagas.json processado. 14081 vagas encontradas.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nProcessando vagas.json...\")\n",
    "with open('../data/raw/vagas.json', 'r', encoding='utf-8') as f:\n",
    "    vagas_data = json.load(f)\n",
    "\n",
    "processed_vagas = []\n",
    "for vaga_id, data in vagas_data.items():\n",
    "    record = {'id_vaga': vaga_id}\n",
    "    if isinstance(data.get('informacoes_basicas'), dict):\n",
    "        for key, value in data['informacoes_basicas'].items():\n",
    "            record[f'info.{key}'] = value\n",
    "    if isinstance(data.get('perfil_vaga'), dict):\n",
    "        for key, value in data['perfil_vaga'].items():\n",
    "            record[f'perfil.{key}'] = value\n",
    "    processed_vagas.append(record)\n",
    "\n",
    "vagas_df = pd.DataFrame(processed_vagas)\n",
    "\n",
    "# --- LIMPEZA NA ORIGEM ---\n",
    "# Trata valores nulos (null) e espaços em branco nos campos de idioma\n",
    "if 'perfil.nivel_ingles' in vagas_df.columns:\n",
    "    vagas_df['perfil.nivel_ingles'] = vagas_df['perfil.nivel_ingles'].fillna('Nenhum').str.strip()\n",
    "if 'perfil.nivel_espanhol' in vagas_df.columns:\n",
    "    vagas_df['perfil.nivel_espanhol'] = vagas_df['perfil.nivel_espanhol'].fillna('Nenhum').str.strip()\n",
    "print(\"Níveis de idioma das vagas foram limpos e padronizados.\")\n",
    "# --- FIM DA LIMPEZA ---\n",
    "\n",
    "print(f\"vagas.json processado. {len(vagas_df)} vagas encontradas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bloco 2: Processar `prospects.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processando prospects.json...\n",
      "prospects.json processado. 53759 candidaturas encontradas.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nProcessando prospects.json...\")\n",
    "with open('../data/raw/prospects.json', 'r', encoding='utf-8') as f:\n",
    "    prospects_data = json.load(f)\n",
    "\n",
    "prospects_list = []\n",
    "for vaga_id, data in prospects_data.items():\n",
    "    for prospect in data.get('prospects', []):\n",
    "        if prospect: \n",
    "            prospect_info = {\n",
    "                'id_vaga': vaga_id,\n",
    "                **prospect\n",
    "            }\n",
    "            prospects_list.append(prospect_info)\n",
    "\n",
    "prospects_df = pd.DataFrame(prospects_list).add_prefix('prospect.')\n",
    "prospects_df.rename(columns={'prospect.id_vaga': 'id_vaga'}, inplace=True)\n",
    "print(f\"prospects.json processado. {len(prospects_df)} candidaturas encontradas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bloco 3: Processar `applicants.json` e Aplicar Filtros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processando applicants.json...\n",
      "Dados dos candidatos foram achatados (flattened).\n",
      "Níveis de idioma dos candidatos foram limpos e padronizados.\n",
      "42482 candidatos brutos carregados.\n",
      "Aplicando filtro de qualificações no CV...\n",
      "34447 candidatos removidos.\n",
      "8035 candidatos válidos restantes.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nProcessando applicants.json...\")\n",
    "applicants_raw_df = pd.read_json('../data/raw/applicants.json', orient='index')\n",
    "applicants_raw_df.index.name = 'id_candidato'\n",
    "\n",
    "# Achatamento (flattening) dos dados do candidato\n",
    "nested_columns = [\n",
    "    'infos_basicas', 'informacoes_pessoais', 'informacoes_profissionais', \n",
    "    'formacao_e_idiomas', 'cargo_atual'\n",
    "]\n",
    "df_parts = [applicants_raw_df.drop(columns=nested_columns, errors='ignore')]\n",
    "\n",
    "for col in nested_columns:\n",
    "    if col in applicants_raw_df.columns:\n",
    "        series_no_na = applicants_raw_df[col].dropna()\n",
    "        if not series_no_na.empty and isinstance(series_no_na.iloc[0], dict):\n",
    "            normalized_part = pd.json_normalize(applicants_raw_df[col]).add_prefix(f\"{col}.\")\n",
    "            normalized_part.index = applicants_raw_df.index\n",
    "            df_parts.append(normalized_part)\n",
    "\n",
    "applicants_df = pd.concat(df_parts, axis=1)\n",
    "applicants_df.reset_index(inplace=True)\n",
    "print(\"Dados dos candidatos foram achatados (flattened).\")\n",
    "\n",
    "# --- LIMPEZA NA ORIGEM ---\n",
    "# Trata valores nulos (null) e espaços em branco nos campos de idioma do candidato\n",
    "if 'formacao_e_idiomas.nivel_ingles' in applicants_df.columns:\n",
    "    applicants_df['formacao_e_idiomas.nivel_ingles'] = applicants_df['formacao_e_idiomas.nivel_ingles'].fillna('Nenhum').str.strip()\n",
    "if 'formacao_e_idiomas.nivel_espanhol' in applicants_df.columns:\n",
    "    applicants_df['formacao_e_idiomas.nivel_espanhol'] = applicants_df['formacao_e_idiomas.nivel_espanhol'].fillna('Nenhum').str.strip()\n",
    "print(\"Níveis de idioma dos candidatos foram limpos e padronizados.\")\n",
    "# --- FIM DA LIMPEZA ---\n",
    "\n",
    "print(f\"{len(applicants_df)} candidatos brutos carregados.\")\n",
    "\n",
    "# Filtro de negócio: manter apenas candidatos que mencionam 'qualificações' no CV\n",
    "print(\"Aplicando filtro de qualificações no CV...\")\n",
    "initial_candidates = len(applicants_df)\n",
    "if 'cv_pt' in applicants_df.columns:\n",
    "    mask = applicants_df['cv_pt'].notna() & applicants_df['cv_pt'].str.contains(\n",
    "        'qualificaç(?:ão|ões)',\n",
    "        case=False, \n",
    "        na=False, \n",
    "        regex=True\n",
    "    )\n",
    "    applicants_filtered_df = applicants_df[mask].copy()\n",
    "    print(f\"{initial_candidates - len(applicants_filtered_df)} candidatos removidos.\")\n",
    "    print(f\"{len(applicants_filtered_df)} candidatos válidos restantes.\")\n",
    "else:\n",
    "    print(\"Aviso: Coluna 'cv_pt' não encontrada. O filtro de qualificações não foi aplicado.\")\n",
    "    applicants_filtered_df = applicants_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bloco 4: Unificar os Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unificando os dados...\n",
      "Unificação concluída.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nUnificando os dados...\")\n",
    "# Garante que as chaves de união sejam do mesmo tipo (string)\n",
    "prospects_df['id_vaga'] = prospects_df['id_vaga'].astype(str)\n",
    "vagas_df['id_vaga'] = vagas_df['id_vaga'].astype(str)\n",
    "prospects_df['prospect.codigo'] = prospects_df['prospect.codigo'].astype(str)\n",
    "applicants_filtered_df['id_candidato'] = applicants_filtered_df['id_candidato'].astype(str)\n",
    "\n",
    "dados_consolidados = pd.merge(prospects_df, vagas_df, on='id_vaga', how='left')\n",
    "dados_consolidados = pd.merge(dados_consolidados, applicants_filtered_df, left_on='prospect.codigo', right_on='id_candidato', how='inner')\n",
    "print(\"Unificação concluída.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bloco 5: Criar a Variável-Alvo (`match`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Criando a variável-alvo 'match'...\n",
      "Variável-alvo criada.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nCriando a variável-alvo 'match'...\")\n",
    "dados_consolidados['match'] = (dados_consolidados['prospect.situacao_candidado'] == 'Contratado pela Decision').astype(int)\n",
    "print(\"Variável-alvo criada.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bloco Final: Análise e Salvamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- BASE DE DADOS CONSOLIDADA ---\n",
      "Dimensões da base final: 13846 linhas, 108 colunas\n",
      "\n",
      "Distribuição da variável-alvo:\n",
      "match\n",
      "0    13073\n",
      "1      773\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Arquivo '../data/processed/dados_consolidados.json' salvo com sucesso!\n",
      "\n",
      "--- ETAPA 1 CONCLUÍDA ---\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- BASE DE DADOS CONSOLIDADA ---\")\n",
    "print(f\"Dimensões da base final: {dados_consolidados.shape[0]} linhas, {dados_consolidados.shape[1]} colunas\")\n",
    "\n",
    "print(\"\\nDistribuição da variável-alvo:\")\n",
    "print(dados_consolidados['match'].value_counts())\n",
    "\n",
    "dados_consolidados.to_json('../data/processed/dados_consolidados.json', orient='records', lines=True, force_ascii=False)\n",
    "print(\"\\nArquivo '../data/processed/dados_consolidados.json' salvo com sucesso!\")\n",
    "print(\"\\n--- ETAPA 1 CONCLUÍDA ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
